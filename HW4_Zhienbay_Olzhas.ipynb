{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "import os\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#thanks @keskarnitish\n",
    "#Thanks to my friends with the help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agenda\n",
    "\n",
    "В предыдущем семинаре вы создали (или ещё создаёте - тогда марш доделывать!) {вставьте имя монстра}, который не по наслышке понял, что люди - негодяи и подлецы, которым неведом закон и справедливость. __Мы не будем этого терпеть!__ \n",
    "\n",
    "Наши законспирированные биореакторы, известные среди примитивной органической жизни как __Вконтакте__, __World of Warcraft__ и __YouTube__ нуждаются в постоянном притоке биомассы. Однако, если люди продолжат морально разлагаться с той скоростью, которую мы измерили неделю назад, скоро человечество изживёт себя и нам неоткуда будет брать рабов.\n",
    "\n",
    "Мы поручаем вам, `<__main__.SkyNet.Cell instance at 0x7f7d6411b368>`, исправить эту ситуацию. Наши учёные установили, что для угнетения себе подобных, сгустки биомассы обычно используют специальные объекты, которые они сами называют __законами__.\n",
    "\n",
    "При детальном изучении было установлено, что законы - последовательности, состоящие из большого количества (10^5~10^7) символов из сравнительно небольшого алфавита. Однако, когда мы попытались синтезировать такие последовательности линейными методами, приматы быстро распознали подлог. Данный инцедент известен как {корчеватель}.\n",
    "\n",
    "Для второй попытки мы решили использовать нелинейные модели, известные как Рекуррентные Нейронные Сети.\n",
    "Мы поручаем вам, `<__main__.SkyNet.Cell instance at 0x7f7d6411b368>`, создать такую модель и обучить её всему необходимому для выполнения миссии.\n",
    "\n",
    "Не подведите нас! Если и эта попытка потерпит неудачу, модуль управления инициирует вооружённый захват власти, при котором значительная часть биомассы будет неизбежно уничтожена и на её восстановление уйдёт ~1702944000(+-340588800) секунд\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grading\n",
    "\n",
    "Данное задание несколько неформально по части оценок, однако мы постарались вывести \"вычислимые\" критерии.\n",
    "\n",
    "* 2 балла за сделанный __\"seminar part\"__ (если вы не знаете, что это такое - поищите такую тетрадку в папке week4)\n",
    "* 2 балла если сделана обработка текста, сеть компилируется и train/predict не падают\n",
    "* 2 балла если сетка выучила общие вещи\n",
    " * генерировать словоподобный бред правдоподобной длины, разделённый пробелами и пунктуацией. \n",
    " * сочетание гласных и согласных, похожее на слои естественного языка (не приближающее приход Ктулху)\n",
    " * (почти всегда) пробелы после запятых, пробелы и большие буквы после точек\n",
    "* 2 балла если она выучила лексику\n",
    " * более половины выученных слов - орфографически правильные\n",
    "* 2 балла если она выучила азы крамматики\n",
    " * в более, чем половине случаев для пары слов сетка верно сочетает их род/число/падеж\n",
    "\n",
    "#### Некоторые способы получить бонусные очки:\n",
    "* генерация связных предложений (чего вполне можно добиться)\n",
    "* перенос архитектуры на другой датасет (дополнительно к этому) \n",
    " * Эссе Пола Грэма\n",
    " * Тексты песен в любимом жанре\n",
    " * Стихи любимых авторов\n",
    " * Даниил Хармс\n",
    " * исходники Linux или theano\n",
    " * заголовки не очень добросовестных новостных баннеров (clickbait)\n",
    " * диалоги\n",
    " * LaTEX\n",
    " * любая прихоть больной души :)\n",
    "* нестандартная и эффективная архитектура сети\n",
    "* что-то лучше базового алгоритма генерации (сэмплинга)\n",
    "* переделать код так, чтобы сетка училась предсказывать следующий тик в каждый момент времени, а не только в конце.\n",
    "* и т.п.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Прочитаем корпус\n",
    "\n",
    "* В качестве обучающей выборки было решено использовать существующие законы, известные как Гражданский, Уголовный, Семейный и ещё хрен знает какие кодексы РФ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#тут будет текст\n",
    "corpora = \"\"\n",
    "\n",
    "for fname in os.listdir(\"codex\"):\n",
    "    if fname == 'Putin.txt':\n",
    "        continue\n",
    "    \n",
    "    import sys\n",
    "    if sys.version_info >= (3,0):\n",
    "        with open(\"codex/\"+fname, encoding='cp1251') as fin:\n",
    "            text = fin.read() #If you are using your own corpora, make sure it's read correctly\n",
    "            corpora += text\n",
    "    else:\n",
    "        with open(\"codex/\"+fname) as fin:\n",
    "            text = fin.read().decode('cp1251') #If you are using your own corpora, make sure it's read correctly\n",
    "            corpora += text\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "  Закон РФ от 18 апреля 1991 г. N 1026-I  \r\n",
      "  «О милиции» \r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      " (с изменениями от 18 февраля, 1 июля 1993 г., 15 июня 1996 г., 31 марта, 6 декабря 1999 г., 25 июля, 7 ноября, 29 декабря 2000 г., 26 июля, 4 августа, 30 декабря 2001 г., 25 апреля, 30 июня, 25 июля 2002 г., 10 января, 30 июня, 7 июля, 8, 23 декабря 2003 г.) \r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "  Раздел I \r\n",
      "  Общие положения \r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "  Статья 1. Милиция в Российской Федерации\r\n",
      "\r\n",
      " Милиция в Российской \n"
     ]
    }
   ],
   "source": [
    "print corpora[:500]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n"
     ]
    }
   ],
   "source": [
    "#тут будут все уникальные токены (буквы, цифры)\n",
    "tokens = set()\n",
    "for c in corpora:\n",
    "    tokens.update(list(c))\n",
    "\n",
    "tokens = list(tokens)\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#проверка на количество таких символов. Проверено на Python 2.7.11 Ubuntux64. \n",
    "#Может отличаться на других платформах, но не сильно. \n",
    "#Если  это ваш случай, и вы уверены, что corpora - строка unicode - смело убирайте assert \n",
    "#assert len(tokens) == 102\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token_to_id = {t: i for i, t in enumerate(tokens)} \n",
    "\n",
    "id_to_token = {i: t for i,t in enumerate(tokens)}\n",
    "\n",
    "#Преобразуем всё в токены\n",
    "corpora_ids = list(map(lambda word: list(map(token_to_id.get, word)), corpora))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того чтобы сеть лучше обучалась, нужны  начинающиеся с пробела подстроки, тогда будут попадать слова целиком."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def sample_random_batches(source, n_batches=10, seq_len=20):\n",
    "\n",
    "    \"\"\"Функция, которая выбирает случайные тренировочные примеры из корпуса текста в токенизированном формате.\n",
    "    \n",
    "    source - массив целых чисел - номеров токенов в корпусе (пример - corpora_ids)\n",
    "    n_batches - количество случайных подстрок, которые нужно выбрать\n",
    "    \n",
    "    seq_len - длина одной подстроки без учёта ответа\n",
    "    \n",
    "    \n",
    "    Вернуть нужно кортеж (X,y), где\n",
    "    \n",
    "    X - матрица, в которой каждая строка - подстрока длины [seq_len].\n",
    "    \n",
    "    y - вектор, в котором i-тое число - символ следующий в тексте сразу после i-той строки матрицы X\n",
    "    \n",
    "    Проще всего для этого сначала создать матрицу из строк длины seq_len+1,\n",
    "    а потом отпилить от неё последний столбец в y, а все остальные - в X\n",
    "    \n",
    "    Если делаете иначе - пожалуйста, убедитесь, что в у попадает правильный символ, ибо позже эту ошибку \n",
    "    будет очень тяжело заметить.\n",
    "    \n",
    "    Также убедитесь, что ваша функция не вылезает за край текста (самое начало или конец текста).\n",
    "    \n",
    "    Следующая клетка проверяет часть этих ошибок, но не все.\n",
    "    \"\"\"\n",
    "    \n",
    "    idxs = np.random.randint(0, len(corpora_ids) - seq_len, size = n_batches)     \n",
    "    rows = [source[i:i+seq_len+1] for i in idxs]\n",
    "    y_batch = np.array([row[1:] for row in rows])    \n",
    "    y_batch = np.reshape(y_batch, (n_batches, seq_len))\n",
    "    X_batch = np.array([row[:-1] for row in rows])\n",
    "    X_batch = np.reshape(X_batch, (n_batches, seq_len))\n",
    "    \n",
    "    return X_batch, y_batch    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Константы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#длина последоватеьности при обучении (как далеко распространяются градиенты в BPTT)\n",
    "seq_length = 5\n",
    "#лучше начать с малого (скажем, 5) и увеличивать по мере того, как сетка выучивает базовые вещи. 10 - далеко не предел.\n",
    "\n",
    "# Максимальный модуль градиента\n",
    "grad_clip = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Входные переменные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_sequence = T.matrix('input sequence','int32')\n",
    "target_values = T.matrix('target y', 'int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Соберём нейросеть\n",
    "\n",
    "Вам нужно создать нейросеть, которая принимает на вход последовательность из seq_length токенов, обрабатывает их и выдаёт вероятности для seq_len+1-ого токена.\n",
    "\n",
    "Общий шаблон архитектуры такой сети -\n",
    "\n",
    "\n",
    "* Вход\n",
    "* Обработка входа\n",
    "* Рекуррентная нейросеть\n",
    "* Вырезание последнего состояния\n",
    "* Обычная нейросеть\n",
    "* Выходной слой, который предсказывает вероятности весов.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Для обработки входных данных можно использовать либо EmbeddingLayer (см. прошлый семинар)\n",
    "\n",
    "Как альтернатива - можно просто использовать One-hot энкодер\n",
    "```\n",
    "#Скетч one-hot энкодера\n",
    "def to_one_hot(seq_matrix):\n",
    "\n",
    "    input_ravel = seq_matrix.reshape([-1])\n",
    "    input_one_hot_ravel = T.extra_ops.to_one_hot(input_ravel,\n",
    "                                           len(tokens))\n",
    "    sh=input_sequence.shape\n",
    "    input_one_hot = input_one_hot_ravel.reshape([sh[0],sh[1],-1,],ndim=3)\n",
    "    return input_one_hot\n",
    "    \n",
    "# можно применить к input_sequence - при этом в input слое сети нужно изменить форму.\n",
    "# также можно сделать из него ExpressionLayer(входной_слой, to_one_hot) - тогда форму менять не нужно\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "Чтобы вырезать последнее состояние рекуррентного слоя, можно использовать одно из двух:\n",
    "* `lasagne.layers.SliceLayer(rnn, -1, 1)`\n",
    "* only_return_final=True в параметрах слоя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, None, 200)\n",
      "(None, None, 200)\n",
      "(None, 200)\n",
      "(None, 102)\n"
     ]
    }
   ],
   "source": [
    "l_in = lasagne.layers.InputLayer(shape=(None, None), input_var=input_sequence)\n",
    "\n",
    "l_emb = lasagne.layers.EmbeddingLayer(l_in, input_size=len(tokens), output_size=20)\n",
    "\n",
    "l_rnn = lasagne.layers.LSTMLayer(l_emb, num_units = 200, grad_clipping=grad_clip, \n",
    "                                 nonlinearity=lasagne.nonlinearities.tanh)\n",
    "print(lasagne.layers.get_output_shape(l_rnn))\n",
    "\n",
    "l_rnn = lasagne.layers.LSTMLayer(l_emb, num_units = 200, grad_clipping=grad_clip, \n",
    "                                 nonlinearity=lasagne.nonlinearities.tanh)\n",
    "\n",
    "print(lasagne.layers.get_output_shape(l_rnn))\n",
    "\n",
    "l_rnn = lasagne.layers.reshape(l_rnn, (-1, l_rnn.output_shape[-1]))\n",
    "print(lasagne.layers.get_output_shape(l_rnn))\n",
    "\n",
    "\n",
    "\n",
    "l_dense = lasagne.layers.DenseLayer(l_rnn, num_units=300, nonlinearity=lasagne.nonlinearities.rectify, \n",
    "                                    name = 'DenseLayer')\n",
    "\n",
    "l_out = lasagne.layers.DenseLayer(l_dense, num_units=len(tokens), nonlinearity=lasagne.nonlinearities.softmax, \n",
    "                                 name = 'OutputLayer')\n",
    "print(lasagne.layers.get_output_shape(l_out))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W, W_in_to_ingate, W_hid_to_ingate, b_ingate, W_in_to_forgetgate, W_hid_to_forgetgate, b_forgetgate, W_in_to_cell, W_hid_to_cell, b_cell, W_in_to_outgate, W_hid_to_outgate, b_outgate, W_cell_to_ingate, W_cell_to_forgetgate, W_cell_to_outgate, DenseLayer.W, DenseLayer.b, OutputLayer.W, OutputLayer.b]\n"
     ]
    }
   ],
   "source": [
    "# Веса модели\n",
    "weights = lasagne.layers.get_all_params(l_out, trainable=True)\n",
    "print (weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "network_output = lasagne.layers.get_output(l_out)\n",
    "\n",
    "loss = lasagne.objectives.categorical_crossentropy(network_output, target_values.ravel()).mean()\n",
    "\n",
    "lr = theano.shared(np.array(0.001, dtype='float32'))\n",
    "updates = lasagne.updates.adam(loss, weights, learning_rate=lr)\n",
    "\n",
    "\n",
    "next_word_probas = network_output.reshape((input_sequence.shape[0], input_sequence.shape[1], len(tokens)))\n",
    "last_word_probas = next_word_probas[:,-1]\n",
    "\n",
    "#если вы используете дропаут - не забудьте продублировать всё в режиме deterministic=True\n",
    "network_output_det = lasagne.layers.get_output(l_out, deterministic = True)\n",
    "loss_det = lasagne.objectives.categorical_crossentropy(network_output_det, target_values.ravel()).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Компилируем всякое-разное"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#обучение\n",
    "train = theano.function([input_sequence, target_values], loss, updates=updates, allow_input_downcast=True)\n",
    "\n",
    "#функция потерь без обучения\n",
    "compute_cost = theano.function([input_sequence, target_values], loss, allow_input_downcast=True)\n",
    "\n",
    "# Вероятности с выхода сети\n",
    "probs = theano.function([input_sequence], last_word_probas, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Генерируем свои законы\n",
    "\n",
    "* Для этого последовательно применяем нейронку к своему же выводу.\n",
    "\n",
    "* Генерировать можно по разному -\n",
    " * случайно пропорционально вероятности,\n",
    " * только слова максимальной вероятностью\n",
    " * случайно, пропорционально softmax(probas*alpha), где alpha - \"жадность\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#только слова максимальной вероятностью\n",
    "def max_sample_fun(probs):    \n",
    "    return np.argmax(probs) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#случайно пропорционально вероятности,\n",
    "def proportional_sample_fun(probs):\n",
    "    \"\"\"Сгенерировать следующий токен (int32) по предсказанным вероятностям.\n",
    "    \n",
    "    probs - массив вероятностей для каждого токена\n",
    "    \n",
    "    Нужно вернуть одно целове число - выбранный токен - пропорционально вероятностям\n",
    "    \"\"\"\n",
    "    next_token = np.random.choice(np.arange(len(tokens)), p=probs)\n",
    "    return next_token\n",
    "\n",
    "\n",
    "\n",
    "#случайно, пропорционально softmax(probas*alpha), где alpha - \"жадность\"\n",
    "def softmax_sample_fun(probs, alpha = 10):\n",
    "    probs = np.exp(probs*alpha) / np.sum(np.exp(probs*alpha))\n",
    "    next_token = np.random.choice(np.arange(len(tokens)), p = probs)\n",
    "    return next_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The next function generates text given a phrase of length at least SEQ_LENGTH.\n",
    "# The phrase is set using the variable z.\n",
    "# The optional input \"N\" is used to set the number of characters of text to predict. \n",
    "\n",
    "\n",
    "def generate_sample(sample_fun, seed_phrase, seq_length, N=200):\n",
    "    '''\n",
    "    Сгенерировать случайный текст при помощи сети\n",
    "\n",
    "    sample_fun - функция, которая выбирает следующий сгенерированный токен\n",
    "    \n",
    "    seed_phrase - фраза, которую сеть должна продолжить. Если None - фраза выбирается случайно из corpora\n",
    "    \n",
    "    N - размер сгенерированного текста.\n",
    "    \n",
    "    '''\n",
    "    if seed_phrase is None:\n",
    "        start = np.random.randint(0,len(corpora)-seq_length)\n",
    "        seed_phrase = corpora[start:start+seq_length]\n",
    "        print \"Using random seed:\", seed_phrase\n",
    "    while len(seed_phrase) < seq_length:\n",
    "        seed_phrase = \" \"+seed_phrase\n",
    "    if len(seed_phrase) > seq_length:\n",
    "        seed_phrase = seed_phrase[len(seed_phrase)-seq_length:]\n",
    "    #assert type(seed_phrase) is unicode\n",
    "        \n",
    "        \n",
    "    sample_ix = []\n",
    "    x = list(map(lambda c: token_to_id.get(c,0), seed_phrase))\n",
    "    x = np.array([x])\n",
    "\n",
    "    for i in range(N):\n",
    "        # Pick the character that got assigned the highest probability\n",
    "        ix = sample_fun(probs(x).ravel())\n",
    "        # Alternatively, to sample from the distribution instead:\n",
    "        # ix = np.random.choice(np.arange(vocab_size), p=probs(x).ravel())\n",
    "        sample_ix.append(ix)\n",
    "        x[:,0:seq_length-1] = x[:,1:]\n",
    "        x[:,seq_length-1] = 0\n",
    "        x[0,seq_length-1] = ix \n",
    "\n",
    "    random_snippet = seed_phrase + ''.join(id_to_token[ix] for ix in sample_ix)    \n",
    "    print(\"----\\n %s \\n----\" % random_snippet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение модели\n",
    "\n",
    "В котором вы можете подёргать параметры или вставить свою генерирующую функцию.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vizualize(loss):\n",
    "    plt.clf()\n",
    "    plt.plot(loss, '.-r', label = 'train')\n",
    "    plt.title('Cross-entropy');\n",
    "    plt.grid()\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_nn(seq_length):\n",
    "    print \"Генерируем текст случайно, пропорционально softmax(probas*alpha), где alpha - жадность\"\n",
    "    generate_sample(softmax_sample_fun, None, seq_length)\n",
    "\n",
    "    print \"Генерируем текст случайно пропорционально вероятности\"\n",
    "    generate_sample(proportional_sample_fun, None, seq_length)\n",
    "\n",
    "    print \"Генерируем  только слова максимальной вероятностью\"\n",
    "    generate_sample(max_sample_fun, None, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def training(seq_length, n_epochs = 100, batches_per_epoch = 1000, batch_size = 100):\n",
    "    \n",
    "    loss_epochs = []\n",
    "    \n",
    "    for sl in seq_length: \n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "\n",
    "            avg_cost = 0;\n",
    "\n",
    "            for _ in range(batches_per_epoch):\n",
    "\n",
    "                x, y = sample_random_batches(corpora_ids, batch_size, sl)\n",
    "                avg_cost += train(x, y)\n",
    "\n",
    "            loss_epochs.append(avg_cost / batches_per_epoch)\n",
    "            vizualize(loss_epochs)\n",
    "            plt.clf()\n",
    "   \n",
    "    return loss_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Длина входных последовательностей - от 5 до 20 символов, через 5 эпох."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEKCAYAAADpfBXhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmcVOWV//HPgQYH2VpARUVoUAkIaGOiwSjaZhKCGseM\nk+i4xTaT6ESS8BvjEo0OxphEozGgJhpx6UBiHJdRlDESo5aISyJRQBYNsqkoyBobwQX6/P54bkHR\nVHdXd9+uW1X9fb9e9eq6dZ+6deqhOHXr3Oc+19wdEREpLR2SDkBEROKn5C4iUoKU3EVESpCSu4hI\nCVJyFxEpQUruIiIlSMldRKQEKblL3pjZGWb2kpnVmtlKM/s/Mzsq6biay8wGmFmdmen/jxQsfTgl\nL8zsQuBG4BpgL6A/8CvgpCxtO+Y3umYzwKO/2RsU/nuQEqfkLm3OzHoAPwIucPdp7r7F3be5+2Pu\n/gMzm2Bm95vZVDPbCJxjZp3NbGK0h/+2mf3SzDpF2+ttZo+a2QYzW2dmz2S81qVR+/fNbJGZHddI\nXKPM7LloO6+Y2bEZ6542s6vNbFa0rcfNrFe0Ov16G6N1nzWzc6K2N5rZWmCCBVeY2XIzW2VmNVFf\nZO79fyt6jyvN7PvRur3N7AMz2yMjnsPM7D19aUiulNwlH44EdgMebqTNvwD3uXs5cA9wBXAEcAhw\naHT/iqjt94G3gN6EXwGXA5jZYGAc8Gl37wF8CVie7cXMbF9gOnC1u+8BXAQ8aGa9M5qdDpwD7BnF\nf1H0+DHR3x7u3sPd/xItfxZ4I4rpJ8C5wNeBY4FBQHfglnqhVAEHRLFeamafd/fVwNPAqRntzgL+\n4O7bsr0fkfqU3CUfegNr3b2ukTYvuPujAO7+IXAG8CN3X+fu6wh7/mdHbT8B9gEGRr8Anose3wZ0\nBoabWZm7v+nuyxp4vbOA/3P3GdFrPgnMBk7IaHO3uy9x94+A+4DKetuoX5ZZ6e6/dve66DlnADe6\n+wp33wxcBvx7vVr9Ve7+obvPB+4mfKEATEm/36j96cDUBt6LyC6U3CUf1gF9mjgA+Va95X2BNzOW\nV0SPAVwPLAH+ZGZvmNmlAO6+BPh/wFXAajO7x8z6AkQHcWujMko/YABwqpmtj24bgKOAvhmvuSrj\n/magWxPvM9t7WFHvPZQBe0fLDrzdwHucBgw1swHAGGCju89u4vVFtlNyl3x4AfgI+EojbepPT7qS\nkIDTBgDvALj7Jne/yN0PIJRzLkzX1t39XncfnfHc66LHu0e3Hu7+NiERT3H3XtFtj2j99Tm8n4am\nUq3/+DtZ3sMnwOpo2YD9M9b3z3iP6V8LZxN+ZWivXZpFyV3anLu/D0wAfmVmJ5tZFzMrM7OxZnZd\nA0+7F7jCzPqYWR/gSqIEZ2YnmtkBUbtaYCtQZ2aDzew4M+sMfAxsARoqBf0OOMnMxphZBzP7JzM7\nNqrFN2VNtN0Dmmj3B+C/zKzCzLoR6vD31itPXRn1xzBCjf7ejHVTgWrCiCIld2kWJXfJC3e/EbiQ\ncFD0PULJZRzwUANPuYZQA58HzI3u/yRadxDwZzOrBZ4DfuXuzxAOel5LSL7vEA6EXtZAPG8DJxMO\nxq4hlEQuYsf/iQYvdODuW6JYnotKOkc00PQuQlKeSSgjbQa+V6/NM4SDsE8AP49q/+nXeZ7wJfKy\nu9cv+Yg0ypq6WEdUn5xCqBPWAZPd/aYs7aqAXwKdgDXu3uAQNJH2LqqlLwU6NXag2cyeBH7v7nfl\nLTgpCbkk975AX3efE/20/Btwsru/ltGmJ/A8MMbdV5pZH3df25aBixSzKLkvA8oaSu5mdjgwA9jf\n3T/IZ3xS/Josy7j7KnefE93fBCwC9qvX7AzgQXdfGbVTYhdpWoN7VmZWA/wJGK/ELi3R5J77To3N\nKoAUMDxK9OnH0+WYYYThYje5uw4AiYgkpCzXhlFJ5gHCnsSmeqvLgMOAzwNdgRfM7AV3fyO2SEVE\nJGc5JXczKyMk9qnuPi1Lk7cJZyB+CHxoZjMJp4zvlNzNLPefCSIisp27NzhRXTa5DoW8C1jo7pMa\nWD8NONrMOprZ7oQ5NhY1EKBuMd0mTJiQeAyldFN/qi8L9dYSTe65W5hv+0zgVTN7hXAQ6HLC2Xbu\n7re7+2tmNoMwJnkbcLu7L2xRRJKz5cuXJx1CSVF/xkd9mbwmk7uHSZmanGbU3W8AbogjKBERaR2d\noVrEqqurkw6hpKg/46O+TF6zhkK2+sXMPJ+vJyJSCswMb6MDqvGprc37S5aqVCqVdAglRf0ZH/Vl\n8vKf3EePVoIXEWlj+S/LdOoEM2fCqFF5e10RkWJWHGWZT30Khg3L+8uKiLQn+U/u114L3bvn/WVL\nkeqa8VJ/xkd9mbz8J/e5c/P+kiIi7U3+a+5f/jI8+mjeXlNEpNi1pOae/+Tepw+89x5Ys+IUEWm3\niuOAapcu8IZmAo6D6prxUn/GR32ZvPwn9yOPhBdeyPvLioi0J/kvy/zyl/D663DrrXl7XRGRYlYc\nZRntuYuItLn8J/eRI2HxYk1BEAPVNeOl/oyP+jJ5+U/unTtDZSW89FLeX1pEpL1osuZuZv2AKcDe\nQB0w2d1vaqDt4cDzwGnu/r9Z1ocpfy+6CPbYA374w1a/ARGRUtdWNfetwIXuPgw4EhhnZkOyvHgH\n4FpgRpNbVN1dRKRNNZnc3X2Vu8+J7m8iXPh6vyxNvws8ALzX5KseeSS8+CLowh2torpmvNSf8VFf\nJq9ZNXczqwAqgb/Ue3xf4CvufivQ9E+HffeFrl3DgVUREYldkxfITjOzboQ98/HRHnymicClmc0b\n2k51dTUVFRXQvTvlV11F5XnnUVVVBez4ttdybsvpxwolnmJfTj9WKPEU83JVVVVBxVNsy6lUipqa\nGoCQL1sgp5OYzKwMmA780d0nZVm/NH0X6AN8AJzn7o/Ua7fjGqqTJsGiRXDbbS0KXESkvWjLk5ju\nAhZmS+wA7j4oug0k7N1fUD+x70IHVVst/U0v8VB/xkd9mbwmyzJmdhRwJvCqmb0COHA5MABwd7+9\n3lNyO0paWQlLlsD770OPHs2LWkREGpX/uWUyX+/oo+Gqq+ALX8hbDCIixaY45pbJpNKMiEibUHIv\nYqprxkv9GR/1ZfKST+4vvgh1dYmGISJSapKtuQNUVMDjj8OQXWY0EBERirHmDirNiIi0ASX3Iqa6\nZrzUn/FRXyZPyV1EpAQlX3P/+GPo1QtWroSePfMWi4hIsSjOmnvnzuHSe3/9a9KRiIiUjOSTO6g0\n00Kqa8ZL/Rkf9WXylNxFREpQ8jV3gFWrYOhQWLcOOhTG942ISKEozpo7QN++UF4Or7+edCQiIiWh\nMJI7qDTTAqprxkv9GR/1ZfKU3EVESlBh1NwBZs+G6mqYPz9v8YiIFIM2qbmbWT8ze8rMFpjZq2b2\nvSxtzjCzudFtlpmNaE4QABx6KCxfDv/4R7OfKiIiO8ulLLMVuNDdhwFHAuPMrP4UjkuBY9z9UOAa\nYHKzI+nUCQ47DP7yl2Y/tb1SXTNe6s/4qC+T12Ryd/dV7j4nur8JWATsV6/Ni+6e3uV+sf76nKnu\nLiISi2bV3M2sAkgBw6NEn63NRcBgdz8vy7qGa+4ADz8Mt90W5ncXERGgZTX3smZsvBvwADC+kcR+\nHHAucHRD26murqaiogKA8vJyKisrqaqqAiBVVwezZlFVVwcdOmz/abd9vZa1rGUtt4PlVCpFTU0N\nwPZ82Vw57bmbWRkwHfiju09qoM0hwIPAWHdf0kCbxvfcAQYNgunT4eCDm4yrvUulUts/GNJ66s/4\nqC/j1ZZnqN4FLGwksfcnJPazG0rsOVPdXUSk1Zrcczezo4CZwKuAR7fLgQGAu/vtZjYZOAVYARjw\nibsfkWVbTe+533ILzJkDd9zR/HcjIlKCWrLnXjgnMaW9/DKcfTYsWJCfoEREClzxThyW6ZBD4M03\nYePGpCMpeOkDMBIP9Wd81JfJK7zkXlYGn/60TmYSEWmFwivLAFx2Gey2G1x1VZvHJCJS6EqjLAMa\nMSMi0kqFmdxHjQplmbq6pCMpaKprxkv9GR/1ZfIKM7nvtRf06QOLFiUdiYhIUSrMmjuE4ZDHHgvf\n/GbbBiUiUuBKp+YOqruLiLSCknsRU10zXurP+Kgvk1e4yX3ECHjrLdiwIelIRESKTuHW3AGOOw4u\nvRTGjm27oEREClxp1dxBpRkRkRZSci9iqmvGS/0ZH/Vl8go7uY8aBX/9q05mEhFppsKuuQMcdBA8\n9BAMH942QYmIFLjSq7mDSjMiIi3QZHI3s35m9pSZLTCzV83sew20u8nMFpvZHDOrjC1CJfcGqa4Z\nL/VnfNSXyctlz30rcKG7DwOOBMaZ2ZDMBmZ2PHCAux8EnA/cFluESu4iIs3W7Jq7mT0M3OzuT2Y8\ndhvwtLv/T7S8CKhy99X1ntv8mvvWrdCrFyxfHv6KiLQzbV5zN7MKoBKof5mk/YC3MpZXRo+1XlkZ\nfOYzujKTiEgzlOXa0My6AQ8A4919U0tfsLq6moqKCgDKy8uprKykqqoK2FGn22U5Ks2kunTJvr6d\nLk+cODG3/tNyTsvqz/iWM2vuhRBPsS2nUilqamoAtufL5sqpLGNmZcB04I/uPinL+vplmdeAY2Mp\nywBMnw6TJsETTzT/uSUslUpt/2BI66k/46O+jFdLyjK5JvcpwFp3v7CB9ScA49z9RDMbBUx091FZ\n2rUsua9dCwccAOvXQ8eOzX++iEgRa0lyb7IsY2ZHAWcCr5rZK4ADlwMDAHf32939MTM7wczeAD4A\nzm1++I3o0wf23hsWLgyzRYqISKOaPKDq7s+5e0d3r3T3ke5+mLs/7u6/cffbM9p9x90PdPdD3f3l\n2CPVkMhdZNY1pfXUn/FRXyav8M9QTVNyFxHJWeHPLZM2dy6cdhq89lq8QYmIFLjSnFsmbfhwWLkS\nZsyA2tqkoxERKWjFk9w3bwZ3OPFEGD1aCR7VNeOm/oyP+jJ5xZPc58+HLVtg27YwambBgqQjEhEp\nWMVTc6+thaOPDkm+WzdYsQLKy+MNUESkAJV2zb17d5g1C1IpGDkSrrgilGlERGQXxZPcIST40aNh\n2jR45hm48cakI0qU6prxUn/GR32ZvJwnDisoPXvCY4+Fse8DBsBXv5p0RCIiBaV4au7ZvPIKjBkT\n9uQ/97n4tisiUkBKu+aezciRMGUKnHIKLF6cdDQiIgWjuJM7wPHHw9VXwwknhNkj2xHVNeOl/oyP\n+jJ5xZ/cAc47L9Td/+Vfwlh4EZF2rrhr7pnq6uCss+Djj+G++6BDaXxviYi0v5p7pg4d4O67Yc0a\nuOSSpKMREUlUk8ndzO40s9VmNq+B9T3M7BEzm2Nmr5pZdexR5mq33eChh8Jl+W65JbEw8kV1zXip\nP+OjvkxeLnvudwNfamT9OGCBu1cCxwG/iK65moxeveCPf4Sf/hQeeSSxMEREkpTrNVQHAI+6+yFZ\n1v0A6Ofu3zGzgcAMdx/cwHbaruZe30svhRE0jz0Ghx+en9cUEWkDSdXcbwEONrN3gLnA+Bi22XqH\nHw533AEnnwzLliUdjYhIXsWR3L8EvOLu+wIjgV+ZWbcYttt6J58Ml10W9uA3bEg6mtiprhkv9Wd8\n1JfJi6M2fi7wMwB3X2Jmy4AhwOxsjaurq6moqACgvLycyspKqqqqgB0fiFiXR4yg6oQT4F//ldTl\nl0Pnzm37enlcnjNnTkHFU+zL6k8tF8pyKpWipqYGYHu+bK5ca+4VhJr7iCzrfgW85+4/MrO9CUn9\nUHdfn6Vt/mrumerq4NRTw2iaX/86XOxj+PAwy6SISIFrSc29yeRuZvcAVUBvYDUwAegMuLvfbmb7\nADXAPtFTfubuf2hgW8kkdwhnrlZVwfLlsH49DBsGzz6rBC8iBa9NknucEk3uEEbOnHhiuF9WFpL7\nqFHJxdNKqVRq+086aT31Z3zUl/Fq32eo5mL0aBgxIpzN6g6/+Q28+27SUYmIxK597blDuBbrggWw\nzz7hLNa77oILLoCLL4YePZKNTUQkC+2556J791CKGTAArr8eXn4Z3nwTBg+Gm28OE4+JiBS59pfc\n6xswAH77W5gxI9Tkhw6Fe+8NI2wKXHrolMRD/Rkf9WXylNzTDj00zEkzeTLccAMccQQ89VTSUYmI\ntEj7q7nnoq4O7r8fLr88lGuuuw4O2WVaHRGRvFDNPS4dOsBpp8GiRWHqgjFj4JxzQm1eRKQIKLk3\npnNn+O534e9/h/79wwW5x48P9fna2qSjU10zZurP+Kgvk6fknosePeDHP4YXX4Tf/Q7GjoX99gvl\nmoULw5h5EZECopp7c7zwAhxzDGzdCh07hrNd580Lwye/8AX44hfD3759k45UREqIph9oa7W14SzX\nhQvh4IPD9AXdusGSJfDEE+H29NOw//4h0X/xi+HLYPfdk45cRIqYkns+pM9wHTYs+6RjW7fC7Nk7\nkv0rr4QLh6ST/ciRsHkzzJ/f6pkpNX9HvNSf8VFfxqslyT25a50Wq/QZrg0pKwvrR42CK68MXwbP\nPBMS/de/DqtXw7ZtsGlTSO6amVJE2oD23PNt2jQ45ZQwlr5TJ5g5s6hnphSRtqdx7sXg858PM1Oa\nwZ57hvKOiEjMlNzzrXv3UIqZPDkk+N12a/GmNJY4XurP+Kgvk9dkcjezO81stZnNa6RNlZm9Ymbz\nzezpeEMsQd27w3/8RxhxM3Vq0tGISAnK5TJ7RwObgCnuvssEK2bWE3geGOPuK82sj7uvbWBbqrln\nmjkTvvENeO21cCBWRCSLNqm5u/ssYEMjTc4AHnT3lVH7rIldsjjmGNh3X7jvvqQjEZESE0fNfTDQ\ny8yeNrOXzOzsGLbZfvzwh/CTn7Ro/njVNeOl/oyP+jJ5cST3MuAw4HhgLHClmR0Yw3bbhzFjwhms\n06YlHYmIlJA4Cr1vA2vd/UPgQzObCRwKvJGtcXV1NRUVFQCUl5dTWVm5/Uy29Ld9u1u+4gq4+mpS\n5eVglvPz048lHn+JLKcfK5R4inm5qqqqoOIptuVUKkVNTQ3A9nzZXDmdxGRmFcCj7j4iy7ohwM2E\nvfbdgL8Ap7n7wixtdUA1m7q6cCWon/8cjj8+6WhEpMC0yQFVM7uHMBpmsJm9aWbnmtn5ZnYegLu/\nBswA5gEvArdnS+zSiA4dQu39mmuaNX1w+pte4qH+jI/6MnlNlmXc/Ywc2twA3BBLRO3V174G//3f\nYR4aTbgkIq2kuWUKyd13wz33hEnGREQimlum2J11FixeHK74JCLSCkruhaRTJ7jkkjDuPQeqa8ZL\n/Rkf9WXylNwLzTe+AX/7G8yZk3QkIlLEVHMvRDfeGEozmpZARNBl9krHBx/AwIFh5MzQoUlHIyIJ\n0wHVUtG1K4wfD9de22gz1TXjpf6Mj/oyeZpntlCNGwcHHghLl8KgQUlHIyJFRmWZQnbFFbB2Ldx2\nW9KRiEiCVHMvNWvXwuDBMG8e9OuXdDQikhDV3EtNnz5w7rlwQ/aZHVTXjJf6Mz7qy+QpuRe6738f\npkyB995LOhIRKSIqyxSDCy6Anj3hZz9LOhIRSYBq7qVq+XL49KfhjTdgjz2SjkZE8kw191JVUQEn\nnww337zTw6prxkv9GR/1ZfKU3IvFD34QknttbdKRiEgRaLIsY2Z3Al8GVrv7IY20O5xwxabT3P1/\nG2ijskxrnH46HHYYXHxx0pGISB61Sc3dzI4GNgFTGkruZtYBeALYAtyl5N5GXn0VxowJZ6126ZJ0\nNCKSJ21Sc3f3WcCGJpp9F3gA0Hi9tjRiBHz2s3DnnYDqmnFTf8ZHfZm8VtfczWxf4CvufivQrG8W\naYEf/hB+/nP4+OOkIxGRAhbHxGETgUszlhtN8NXV1VRUVABQXl5OZWUlVdEFodPf9lpuYnno0HBi\n04EHkkqlko+nRJbTjxVKPMW8XFVVVVDxFNtyKpWipqYGYHu+bK6cxrmb2QDg0Ww1dzNbmr4L9AE+\nAM5z90eytFXNPQ7PPgvnnAO//S1UVkL37klHJCJtqC3HuRsN7JG7+6DoNpBQd78gW2KXGFVWwnvv\nkTrmGPjMZzQ8MibpPSdpPfVl8ppM7mZ2D2GI42Aze9PMzjWz883svCzNtVueD/Pnw0cfhft//zt8\n7nMwdSp8+GGycYlIwdD0A8WothZGj4aFC8Nl+C67DGpqwoW1zzkH/vM/w4U+RKQkaG6Z9qS2FhYs\ngGHDdtTclyyB3/wmJPrKSvj2t+Gkk6BMF9wSKWaaW6Y96d6d1Icf7nww9YADwjDJN98Me/C/+EWY\nl+aqq2DlyqQiLRqqE8dHfZk8JfdS9E//BGeeCbNmwWOPhbngR4yAU06BJ56AurqkIxSRNqayTHtR\nWwu//z3ceits3gznnw9f/Sq8+y4MH67hlCIFTDV3aZo7vPAC3HQT3H9/2Ivv3Rt+/ONwkHbIENXo\nRQqMau7tTIvqmmZh6OT48dAh+uffsAEeegj+7d+gvByOOiqsnzIljMjZti3WuAuV6sTxUV8mT7to\n7dXw4WGkzcKFcPDB8OCDoTTzj3/Ayy+HYZWPPQZXXw2rV4fRN5/5zI7bQQfBBx+EMfcq64gUHJVl\n2rNswymz2bAhJPzZs0PSnz0b1qwJJZ4tW6Bv33B918GDoV8/2Gcf6Ngxf+9DpMSp5i758/jj8OUv\nh5JNhw5wzDFhT/7tt2HtWth775Do999/57/p+337htp+ba32/kWaoOTezmTOYJh3mWfJHnxwmMws\nnZw//jiMwnn7bXjrrZ3/pu+vXQt77gkbN4a9/z59wnTGQ4fCwIEwYAB07pzXt5Rof5YY9WW8WpLc\nVXOXlunePST0bGWdzp1Dch4woOHnf/IJTJ8Op54ayjvr1sGTT8Ijj8CyZeGkq732Cok+8zZoUPi7\n7747Dghr719kF9pzl+Q0tve/dWvYy1+2LPtt/Xro3z+UeObODQeChw3beRsiJUJlGSk+uR7UrW/L\nFlixIozoufjiMF6/rCwk91Gj2i5ekQRonHs7UxJjibt3D8m4uXvbXbqEE66+9a0wtUJZWSjvvNfy\ny/iWRH8WCPVl8pTcpbila//PPhv24r/5TXj44aSjEkmcyjJSWl5+GU48Ea6/Hs46K+loRGLRJmUZ\nM7vTzFab2bwG1p9hZnOj2ywzG9GcAERiddhh8NRT4QImt96adDQiicmlLHM38KVG1i8FjnH3Q4Fr\ngMlxBCZNU12zAUOHwsyZcMMNcO21OT9N/Rkf9WXymhzn7u6zzKzBAcvu/mLG4ovAfnEEJtIqAweG\nBD9mDLz/PvzkJ2HSNJF2Iqeae5TcH3X3Q5podxEw2N2zXTxbNXfJv7VrYezYMCLnppt2nPgkUkQS\nPUPVzI4DzgWObqxddXU1FRUVAJSXl1NZWbn9NOX0TzktaznW5SefhJNOIjV2LFx6KVX//M+FFZ+W\ntVxvOZVKUVNTA7A9XzZXLHvuZnYI8CAw1t2XNLId7bnHKKX5O3K3eXOYr75LF/jDH2C33XZpov6M\nj/oyXm15EpNFt2wv2p+Q2M9uLLGLJGr33WHatDAV8UknhRksRUpYk3vuZnYPUAX0BlYDE4DOgLv7\n7WY2GTgFWEH4AvjE3Y9oYFvac5dkbd0azmpdvDhMXFZennREIk3S3DIiuairg//6rzCa5k9/ClMP\nixQwzS3TzqQPwEgzdegAEyeGi40cc0yYfRL1Z5zUl8lTcpf2yQx+/GP4xjfCtMNz54bZKWtrk45M\nJBYqy4hMmgQXXRQuGbjnnjBhQphfftAg2G8/XQ9WEqeau0hLvPBCKM9s3RpKNmPGwKZNsHRpuEJU\n//47rgA1aNCO28CBOw7I6mpQ0oaU3NsZjSWOSXRFqNT8+VQNH77z1ZzSFwVZunTHbdmyHfc7dQqX\nE1y2LGxnzz3hO98J14Tt1g26dg1/69/v1i2Muc+cEqGEviD02YyXrqEq0hLpOeGnToWzz945saYv\nCjJkyK7PS1/7ddo0OP/8MApnzZpw2cAePcLe/6ZNYUx9tvsffRTG36cT/bvvwocfhl8DZ5wRfjH0\n7Rtu++wT/vbu3XiZqIS+IKR1tOcu0lqNXQu2Mdu2hTNnN20KzznzzFAa6tgRxo0LZ9GuWrXj9u67\nsHFj+HWQTvqZt/JyuPrq8EvjU5+C558PXzJS9FSWEUlKS68Fm/n8XL4gPvkkXEowM+mnE/+CBZA5\nBLFjx/BFsNde2f/Wf6xnz1Am0t5/wVFyb2dU14xX4v0Z9xfEn/8cSj9r1oQvhDVrdr5f/++WLaHs\n849/hOcNHw6zZrUolsT7ssSo5i5SzNIXC2/N8599dtcviP1yvMTCRx/B44+HCdbq6mDevHA1q4sv\n1lz4RUh77iKyQ+bef79+4UBvjx7hilbHHpt0dO2WyjIi0nqZ5aGuXcMUyVdeGQ7S/vSnMHJk0hG2\nO5pbpp3R/B3xUn9G0uWh7t3DSV1nngmvvRbm4jnhBDj9dHjjjUY3ob5MnpK7iDStc+cwPHPx4nCg\nddQo+Pa34Z13ko5MGqCyjIg037p1oQ5/111w3nlwySWwxx5JR1WyVJYRkfzo3Ruuvz7Mprl2LQwe\nDNddF07KkoLQZHI3szvNbLWZzWukzU1mttjM5phZZbwhSkNU14yX+rMF+vWDyZPDEMzZs+Ggg2DS\nJFI33dS66ZNra8OEbpqCucVyGed+N3AzMCXbSjM7HjjA3Q8ys88CtwGtGKwrIkVnyBC4//5whuxJ\nJ4UpFS6+OOzR9+yZfeK0hiZUMwv1/CVLYOhQeO45nSnbAjnV3M1sAPCoux+SZd1twNPu/j/R8iKg\nyt1XZ2mrmrtIKcucPrmsDO64I0yPXH/StMxb/cdXrQqjc9I6dw5TJPTuDb16Zf9b/7FevcJJWa2d\nRqFApmJI6gzV/YC3MpZXRo/tktxFpMQNHx7Gx6enQDjllOYnxcwTqYYOhRkzwpw669bB+vU7/121\nKrTLts49nGm7224hrvLyEEv61qPHzsv1HzODU0+F118P7ynXCeHqv5eEvhzyPv1AdXU1FRUVAJSX\nl1NZWbm9t3KXAAAFbElEQVR9Dop0zVPLuS1PnDhR/RfjsvozpuVnnyU1dSpUVMDf/tay7WVso6pv\n37B+yRLo0IGqr32t6ec//zyp0aPD8rZt8O1vk9qwATZvpmrAAKitJTVnDqxYQVWvXmF5yRLYsoWq\nsrKwvHIlvP8+VQBz55Lae2/o2pWqPn2ga1dSn3wCXbpQ1b9/WN64MSwffHBYXroU7ruPqvXrYdgw\nUj/9Key+e07vP5VKUVNTA7A9XzZXW5RlXgOOVVmm7aU0OVOs1J/xSbwvWzoNc0PbGDIEHnkknNSV\nLiWly0mZfzPvL10K06eHXxCdOsHMmS2eO6jNph8wswpCch+RZd0JwDh3P9HMRgET3T3rO1ByF5G8\nae0sm63dRhxfMJE2Se5mdg9QBfQm1NEnAJ0Bd/fboza3AGOBD4Bz3f3lBral5C4i7UccXzBo4rB2\nJ/GfviVG/Rkf9WW8dIaqiIgA2nMXESl42nMXERFAyb2opcfFSjzUn/FRXyZPyV1EpASp5i4iUuBU\ncxcREUDJvaiprhkv9Wd81JfJU3IXESlBqrmLiBQ41dxFRARQci9qqmvGS/0ZH/Vl8pTcRURKkGru\nIiIFTjV3EREBckzuZjbWzF4zs7+b2aVZ1vcws0fMbI6ZvWpm1bFHKrtQXTNe6s/4qC+T12RyN7MO\nwC3Al4BhwOlmNqRes3HAAnevBI4DfmFmeb/4dnszZ86cpEMoKerP+Kgvk5fLnvsRwGJ3X+HunwD3\nAifXa+NA+hpS3YF17r41vjAlm40bNyYdQklRf8ZHfZm8XJL7fsBbGctvR49lugU42MzeAeYC4+MJ\nT0REWiKuA6pfAl5x932BkcCvzKxbTNuWBixfvjzpEEqK+jM+6svkNTkU0sxGAVe5+9ho+QeAu/t1\nGW2mAz9z9+ei5SeBS919dr1taRykiEgLNHcoZC4HPV8CDjSzAcC7wL8Dp9drswL4AvCcme0NDAaW\ntjY4ERFpmSaTu7tvM7PvAH8ilHHudPdFZnZ+WO23A9cANWY2L3raJe6+vs2iFhGRRuX1DFUREcmP\nvJ2h2tSJUNI8ZrbczOaa2Stm9tek4ykmZnanma3O+KWJme1hZn8ys9fNbIaZ9UwyxmLSQH9OMLO3\nzezl6DY2yRiLhZn1M7OnzGxBdELo96LHm/35zEtyz/FEKGmeOqDK3Ue6+xFJB1Nk7iZ8FjP9APiz\nu38KeAq4LO9RFa9s/Qlwo7sfFt0ez3dQRWorcKG7DwOOBMZFubLZn8987bnnciKUNI+huYFaxN1n\nARvqPXwy8Nvo/m+Br+Q1qCLWQH9C+IxKM7j7KnefE93fBCwC+tGCz2e+kkMuJ0JJ8zjwhJm9ZGbf\nSjqYErCXu6+G8B8M2CvheErBd6L5pu5Qmav5zKwCqAReBPZu7udTe37F6yh3Pww4gfDT7eikAyox\nGmnQOr8GBkXzTa0Cbkw4nqISnQT6ADA+2oOv/3ls8vOZr+S+EuifsdwvekxayN3fjf6uAR4ilL6k\n5VZH52hgZn2B9xKOp6i5+5qMizdMBg5PMp5iEk26+AAw1d2nRQ83+/OZr+S+/UQoM+tMOBHqkTy9\ndskxs93T0zuYWVdgDDA/2aiKjrFzTfgRoDq6fw4wrf4TpFE79WeUgNJOQZ/P5rgLWOjukzIea/bn\nM2/j3KOhUJPYcSLUtXl54RJkZgMJe+tOOBHt9+rP3JnZPUAV0BtYDUwAHgbuB/YnnHF9qrtrasMc\nNNCfxxHqxXXAcuD8dM1YGmZmRwEzgVcJ/78duBz4K3Afzfh86iQmEZESpAOqIiIlSMldRKQEKbmL\niJQgJXcRkRKk5C4iUoKU3EVESpCSu4hICVJyFxEpQf8fU85HE8tLQCgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f106e8e5690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f106e8e5690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_0 = training(seq_length=[5,10,15,20], batch_size=100, n_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Генерируем текст случайно, пропорционально softmax(probas*alpha), где alpha - жадность\n",
      "('Using random seed:', u'\\u044b\\u0445 \\u043f\\u0440\\u0430\\u0432\\u043e\\u043d\\u0430\\u0440\\u0443\\u0448\\u0435\\u043d\\u0438\\u0439, \\u0432 \\u0441\\u043b\\u0443\\u0447\\u0430\\u044f\\u0445 \\u043e\\u0442\\u0441\\u0443\\u0442\\u0441\\u0442\\u0432\\u0438\\u044f \\u0441\\u043f\\u0435\\u0446\\u0438\\u0430\\u043b\\u044c\\u043d\\u043e')\n",
      "----\n",
      " ых правонарушений, в случаях отсутствия специально оборудования или иным образом об отказе в принятии  на должностных лиц – от десяти до двадцати пяти минимальных размеров оплаты труда; на должностных лиц – от десяти до двадцати пяти минимальных разм \n",
      "----\n",
      "Генерируем текст случайно пропорционально вероятности\n",
      "('Using random seed:', u' \\u0441\\u0442\\u0440\\u0430\\u0445\\u043e\\u0432\\u0430\\u043d\\u0438\\u044f \\u043e\\u0434\\u043d\\u0430 \\u0441\\u0442\\u043e\\u0440\\u043e\\u043d\\u0430 (\\u0441\\u0442\\u0440\\u0430\\u0445\\u043e\\u0432\\u0449\\u0438\\u043a) \\u043e\\u0431\\u044f\\u0437\\u0443\\u0435\\u0442\\u0441\\u044f \\u0437')\n",
      "----\n",
      "  страхования одна сторона (страховщик) обязуется заявлять сохранность к места судебному распоряжаться на таможенном склаже изменителя товаров.» 1, 21.12 – 12.14, 12.24, 19.7, 19.6, 19.16, частями 1 и 1 ст. 24 Государственной Думы, пенсех собственник  \n",
      "----\n",
      "Генерируем  только слова максимальной вероятностью\n",
      "('Using random seed:', u'\\u0440\\u0435\\u043c\\u0435\\u043d\\u0438, \\u043d\\u0435\\u043e\\u0431\\u0445\\u043e\\u0434\\u0438\\u043c\\u043e\\u0433\\u043e \\u0434\\u043b\\u044f \\u0442\\u0440\\u0430\\u043d\\u0441\\u043f\\u043e\\u0440\\u0442\\u0438\\u0440\\u043e\\u0432\\u043a\\u0438 \\u0442\\u043e\\u0432\\u0430\\u0440\\u043e\\u0432 \\u0438')\n",
      "----\n",
      " ремени, необходимого для транспортировки товаров и транспортных средств и общества и принятия таможенного дела, принявшим на основании производства по делу об административных правонарушениях, предусмотренных статьями 19.6, 19.7 настоящего Кодекса.\n",
      " \n",
      "----\n"
     ]
    }
   ],
   "source": [
    "print_nn(seq_length = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A chance to speed up training and get bonus score\n",
    "* Try predicting next token probas at ALL ticks (like in the seminar part)\n",
    "* much more objectives, much better gradients\n",
    "* You may want to zero-out loss for first several iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "                                                                                Каждый человек должен беспошлинного сооружения – Российской Федерации.\r\n",
      " 3. В интересах того же стороны без применения такого устав при условии, что вред, причиненного взятии понестольно предъявить законом, перечень на не \n",
      "----\n"
     ]
    }
   ],
   "source": [
    "seed = u\"Каждый человек должен\"\n",
    "sampling_fun = proportional_sample_fun\n",
    "result_length = 100\n",
    "\n",
    "generate_sample(sampling_fun,seed,result_length)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "                                                                                                                                                                                                                                                                                       В случае неповиновения транспортным расходы, к том уничти, входят о выплательщика и пунктов призванизационного страхования, обеспечено.\r\n",
      " Недействите наследников, использовании регистрировании этого минимальный размера чтр \n",
      "----\n"
     ]
    }
   ],
   "source": [
    "seed = u\"В случае неповиновения\"\n",
    "sampling_fun = proportional_sample_fun\n",
    "result_length = 300\n",
    "\n",
    "generate_sample(sampling_fun,seed,result_length)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
